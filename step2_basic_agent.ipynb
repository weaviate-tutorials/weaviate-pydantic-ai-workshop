{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Adding Tools to Your Agent\n",
    "\n",
    "## The Problem\n",
    "\n",
    "In Step 1, we saw that LLMs can only use their training knowledge. They can't:\n",
    "- Get today's weather\n",
    "- Check live stock prices\n",
    "- Query a database\n",
    "- Make API calls\n",
    "\n",
    "## The Solution: Tools\n",
    "\n",
    "**Tools** are functions that the LLM can call to take actions interact with the world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference:** [Pydantic AI Agents](https://ai.pydantic.dev/agents/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's import what we need. Notice we're now using `Agent` instead of the direct API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This (nest_asyncio) is only required in Jupyter notebooks (https://ai.pydantic.dev/troubleshooting/)\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic_ai import Agent, RunContext\n",
    "from pydantic import BaseModel\n",
    "from tools import get_weather_for_city\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define User Context\n",
    "\n",
    "Agents can be personalized. We'll create a `UserInfo` model to track:\n",
    "- The user's name\n",
    "- The user's city\n",
    "\n",
    "This lets us build context-aware agents that remember who they're talking to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserInfo(BaseModel):\n",
    "    name: str\n",
    "    city: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Agent\n",
    "\n",
    "Now we create an agent instead of making direct API calls.\n",
    "\n",
    "**Key parameters:**\n",
    "- `model`: Which LLM to use\n",
    "- `deps_type`: What type of context/dependencies the agent needs (our `UserInfo`)\n",
    "\n",
    "The agent will have access to user information whenever it runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_agent = Agent(\n",
    "    model=\"anthropic:claude-3-5-haiku-latest\",\n",
    "    deps_type=UserInfo,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the System Prompt\n",
    "\n",
    "Here, we can use system prompt to tell the agent about the user through the dependency object `ctx.deps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@basic_agent.system_prompt\n",
    "def set_system_prompt(ctx: RunContext[UserInfo]) -> str:\n",
    "    return f\"\"\"\n",
    "    You are a helpful assistant.\n",
    "    Answer questions as best you can, using any tools as needed.\n",
    "    The user's name is {ctx.deps.name} and they are in {ctx.deps.city}.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register a Tool\n",
    "\n",
    "This is where the magic happens. The `@basic_agent.tool` decorator registers a function as a tool the agent can call.\n",
    "\n",
    "**Key parts of a tool:**\n",
    "1. **Definition**\n",
    "    - Pydantic AI will automatically generate a docstring from the function's signature and docstring\n",
    "2. **Parameters**\n",
    "3. **Return value**\n",
    "\n",
    "The agent can **choose** whether to call this tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: We've deliberately hidden the tool implementation in this example. It doesn't matter for the agent's decision-making. Take a look at the tool implementation in the `tools.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@basic_agent.tool\n",
    "def get_weather(ctx: RunContext[UserInfo]) -> str:\n",
    "    \"\"\"Check the weather in a given location\"\"\"\n",
    "    print(\">> TOOL USED: Getting weather for user: \", ctx.deps)\n",
    "    return get_weather_for_city(ctx.deps.city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Agent\n",
    "\n",
    "Let's test our agent.\n",
    "\n",
    "**Watch for the \"TOOL USED\" message** - this tells us when the agent decided to call the weather tool!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> TOOL USED: Getting weather for user:  name='JP' city='Edinburgh'\n",
      "It looks like it's a typical Scottish day in Edinburgh - rainy and a bit cool, with temperatures around 9°C. You might want to grab a waterproof jacket and an umbrella if you're heading out today. The rain is quite common in Edinburgh, so it's always good to be prepared!\n"
     ]
    }
   ],
   "source": [
    "model_response = basic_agent.run_sync(\n",
    "    user_prompt=\"What's the weather like today where I am?\",\n",
    "    deps=UserInfo(name=\"JP\", city=\"Edinburgh\"),\n",
    ")\n",
    "print(model_response.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our agent with two different users - here's where our dependency object comes in handy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      ">> RUNNING PROMPT: What's the weather like today where I am?\n",
      ">> FOR USER: JP in Edinburgh\n",
      "============================================================\n",
      ">> TOOL USED: Getting weather for user:  name='JP' city='Edinburgh'\n",
      "\n",
      "Agent response:\n",
      "It looks like a typical Scottish day, JP! The weather in Edinburgh is rainy with temperatures around 5 degrees Celsius. I'd recommend dressing warmly and bringing a waterproof jacket or umbrella if you're planning to go out today.\n",
      "\n",
      "\n",
      "============================================================\n",
      ">> RUNNING PROMPT: What's the weather like today where I am?\n",
      ">> FOR USER: Daniel in Paris\n",
      "============================================================\n",
      ">> TOOL USED: Getting weather for user:  name='Daniel' city='Paris'\n",
      "\n",
      "Agent response:\n",
      "It looks like you're experiencing a bit of a winter wonderland in Paris today! The weather is snowy, which is quite picturesque, and the temperature is a mild 19 degrees Celsius. It might be a good day to enjoy some indoor activities or take a beautiful walk to appreciate the snow if you're dressed warmly. Do you need any recommendations for how to spend a snowy day in Paris?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What's the weather like today where I am?\"\n",
    "\n",
    "for user_info in [\n",
    "    UserInfo(name=\"JP\", city=\"Edinburgh\"),\n",
    "    UserInfo(name=\"Daniel\", city=\"Paris\"),\n",
    "]:\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\">> RUNNING PROMPT: {prompt}\")\n",
    "    print(f\">> FOR USER: {user_info.name} in {user_info.city}\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "\n",
    "    model_response = basic_agent.run_sync(user_prompt=prompt, deps=user_info)\n",
    "\n",
    "    print(f\"\\nAgent response:\")\n",
    "    print(model_response.output)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Just Happened?\n",
    "\n",
    "Let's break down the agent's decision-making:\n",
    "\n",
    "1. **User asks:** \"What's the weather like today where I am?\"\n",
    "2. **Agent thinks:** \"I need current weather data. I can't answer this from my training data alone.\"\n",
    "3. **Agent decides:** \"I should use the `get_weather` tool!\"\n",
    "4. **Tool executes:** Gets weather for the user's city\n",
    "5. **Agent responds:** Uses the tool's result to give a helpful answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "✅ **Agents extend LLMs with tools** - Tools let LLMs access real-time data and take actions  \n",
    "✅ **Agents make decisions** - The LLM decides *when* to use tools based on the question  \n",
    "✅ **Context matters** - We can pass user information to personalize agent behavior  \n",
    "✅ **Docstrings are critical** - The agent reads tool docstrings to understand what they do  \n",
    "\n",
    "### The Pattern\n",
    "\n",
    "```python\n",
    "# 1. Create an agent\n",
    "agent = Agent(model=\"...\", deps_type=YourContextType)\n",
    "\n",
    "# 2. Register tools\n",
    "@agent.tool\n",
    "def your_tool(ctx: RunContext[YourContextType]) -> str:\n",
    "    \"\"\"Clear description of what the tool does\"\"\"\n",
    "    # Do something useful\n",
    "    return result\n",
    "\n",
    "# 3. Run the agent\n",
    "response = agent.run_sync(prompt, deps=context)\n",
    "```\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "In **Step 3**, we'll add multiple tools and see how the agent intelligently chooses between them - or chooses to use *none* when its own knowledge is sufficient!\n",
    "\n",
    "This is where agents really shine. 🌟"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**⏸️ PAUSE: Questions before we continue to Step 3?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
